{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar as calendar\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##scoring functions\n",
    "from sklearn.metrics import r2_score\n",
    "EPSILON = 1e-10\n",
    "def _error(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"Simple error\"\"\"\n",
    "    return actual - predicted\n",
    "def _percentage_error(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"\n",
    "    Percentage error\n",
    "    Note: result is NOT multiplied by 100\n",
    "    \"\"\"\n",
    "    return _error(actual, predicted) / (actual + EPSILON)\n",
    "def mse(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"Mean Squared Error\"\"\"\n",
    "    return np.mean(np.square(_error(actual, predicted)))\n",
    "def rmse(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"Root Mean Squared Error\"\"\"\n",
    "    return np.sqrt(mse(actual, predicted))\n",
    "def mape(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"\n",
    "    Mean Absolute Percentage Error\n",
    "    Properties:\n",
    "        + Easy to interpret\n",
    "        + Scale independent\n",
    "        - Biased, not symmetric\n",
    "        - Undefined when actual[t] == 0\n",
    "    Note: result is NOT multiplied by 100\n",
    "    \"\"\"\n",
    "    return np.mean(np.abs(_percentage_error(actual, predicted)))\n",
    "def mae(actual: np.ndarray, predicted: np.ndarray):\n",
    "    \"\"\"Mean Absolute Error\"\"\"\n",
    "    return np.mean(np.abs(_error(actual, predicted)))\n",
    "METRICS = {\n",
    "    \"mae\": mae,\n",
    "    \"rmse\": rmse,\n",
    "    \"mape\": mape,\n",
    "    \"r2\": r2_score,\n",
    "}\n",
    "def evaluate(actual: np.ndarray, predicted: np.ndarray, metrics=(\"mae\", \"rmse\", \"mape\", \"r2\")):\n",
    "    results = {}\n",
    "    for name in metrics:\n",
    "        try:\n",
    "            results[name] = METRICS[name](actual, predicted)\n",
    "        except Exception as err:\n",
    "            results[name] = np.nan\n",
    "            print(\"Unable to compute metric {0}: {1}\".format(name, err))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Read & clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year of Call Date</th>\n",
       "      <th>Week of Call Date</th>\n",
       "      <th>Day of Call Date</th>\n",
       "      <th>Weekday of Call Date</th>\n",
       "      <th>Total Incoming Calls</th>\n",
       "      <th>Holiday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>792</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>941</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>51</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>948</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>51</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>985</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Call Date  Month  Year of Call Date  Week of Call Date  Day of Call Date  \\\n",
       "0   2020-01-17      1               2020                  3                17   \n",
       "1   2020-01-20      1               2020                  4                20   \n",
       "2   2020-01-21      1               2020                  4                21   \n",
       "3   2020-01-22      1               2020                  4                22   \n",
       "4   2020-01-23      1               2020                  4                23   \n",
       "..         ...    ...                ...                ...               ...   \n",
       "482 2021-12-09     12               2021                 50                 9   \n",
       "483 2021-12-10     12               2021                 50                10   \n",
       "484 2021-12-13     12               2021                 51                13   \n",
       "485 2021-12-14     12               2021                 51                14   \n",
       "486 2021-12-15     12               2021                 51                15   \n",
       "\n",
       "     Weekday of Call Date  Total Incoming Calls  Holiday  \n",
       "0                       6                   296        0  \n",
       "1                       2                   381        1  \n",
       "2                       3                   363        0  \n",
       "3                       4                   305        0  \n",
       "4                       5                   304        0  \n",
       "..                    ...                   ...      ...  \n",
       "482                     5                   882        0  \n",
       "483                     6                   792        0  \n",
       "484                     2                   941        0  \n",
       "485                     3                   948        0  \n",
       "486                     4                   985        0  \n",
       "\n",
       "[487 rows x 8 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"~/Downloads/calls.xlsx\",sheet_name='Sheet 1')\n",
    "df.drop(['INDEX()'],axis=1,inplace=True)\n",
    "df['Call Date'] = pd.to_datetime(df['Call Date'], format=\"%d.%m.%Y\")\n",
    "df['Week of Call Date'] = df['Week of Call Date'].str.replace('Week ','').astype(int)\n",
    "\n",
    "df = df[['Call Date','Month','Year of Call Date','Week of Call Date','Day of Call Date','Weekday of Call Date','Total Incoming Calls']]\n",
    "\n",
    "\n",
    "\n",
    "dr = pd.date_range(start='2015-01-01', end='2024-01-01')\n",
    "cal = calendar()\n",
    "holidays = cal.holidays(start=dr.min(), end=dr.max())\n",
    "\n",
    "df['Holiday'] = df['Call Date'].isin(holidays).astype(int)\n",
    "#df.to_csv('calls.csv',index=False)\n",
    "df\n",
    "\n",
    "#df['Quarter'] = df['Call Date'].dt.quarter\n",
    "#df['Day of year'] = df['Call Date'].dt.dayofyear\n",
    "\n",
    "#df = df.groupby(['Call Date','Year of Call Date','Month','Week of Call Date','Day of Call Date','Weekday of Call Date']).sum('Total Incoming Calls')\n",
    "#df.reset_index(inplace=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Call Date               datetime64[ns]\n",
       "Month                            int64\n",
       "Year of Call Date                int64\n",
       "Week of Call Date                int64\n",
       "Day of Call Date                 int64\n",
       "Weekday of Call Date             int64\n",
       "Total Incoming Calls             int64\n",
       "Holiday                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.843698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.728075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.540021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.453211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.435375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Method     Score\n",
       "2  RandomForestRegressor  0.843698\n",
       "1    KNeighborsRegressor  0.728075\n",
       "0       LinearRegression  0.540021\n",
       "3                  Lasso  0.453211\n",
       "4  DecisionTreeRegressor  0.435375"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Breaking the data and selecting features , predictors\n",
    "predictors=df.drop(['Total Incoming Calls','Call Date'],axis=1)\n",
    "target=df['Total Incoming Calls']\n",
    "x_train,x_cv,y_train,y_cv=train_test_split(predictors,target,test_size=0.2,random_state=42)\n",
    "\n",
    "#Comparing Algorithms\n",
    "def scores(i):\n",
    "    lin = i()\n",
    "    lin.fit(x_train, y_train)\n",
    "    y_pred=lin.predict(x_cv)\n",
    "    lin_r= r2_score(y_cv, y_pred)\n",
    "    s.append(lin_r)\n",
    "#Checking the scores by using our function\n",
    "algos=[LinearRegression,KNeighborsRegressor,\n",
    "       RandomForestRegressor,Lasso,ElasticNet,DecisionTreeRegressor]\n",
    "s=[]\n",
    "for i in algos:\n",
    "    scores(i)\n",
    "\n",
    "models = pd.DataFrame({\n",
    "    'Method': ['LinearRegression', 'KNeighborsRegressor',\n",
    "               'RandomForestRegressor', 'Lasso','DecisionTreeRegressor'],\n",
    "    'Score': [s[0],s[1],s[2],s[3],s[4]]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 69.0965306122449,\n",
       " 'rmse': 102.90352497879374,\n",
       " 'mape': 0.14368885918680566,\n",
       " 'r2': 0.8485066614231392}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsDict = {}\n",
    "predictionsDict = {}\n",
    "\n",
    "#model = RandomForestRegressor(min_samples_leaf=1, min_samples_split=2, n_estimators=100)\n",
    "model = RandomForestRegressor()\n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_cv)\n",
    "#r2_score(y_cv,y_pred)\n",
    "\n",
    "resultsDict['RandomForest'] = evaluate(y_cv, y_pred)\n",
    "predictionsDict['RandomForest'] = y_pred\n",
    "resultsDict['RandomForest']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 72.83096998565051,\n",
       " 'rmse': 105.25071590496313,\n",
       " 'mape': 0.1521933103632873,\n",
       " 'r2': 0.8415168298037337}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reg = xgb.XGBRegressor(objective='reg:squarederror', max_depth=6, colsample_bylevel=0.5, learning_rate=0.01, random_state=20, n_estimators=1000)\n",
    "reg = xgb.XGBRegressor(objective='reg:squarederror',subsample=0.5, n_estimators=1000, max_depth=5, learning_rate=0.01, colsample_bytree=0.8, colsample_bylevel=0.8)\n",
    "\n",
    "reg.fit(x_train, y_train,\n",
    "        verbose=False, early_stopping_rounds=15,eval_set=[(x_cv,y_cv)])  # Change verbose to True if you want to see it train\n",
    "y_pred = reg.predict(x_cv)\n",
    "resultsDict['XGBoost'] = evaluate(y_cv, y_pred)\n",
    "predictionsDict['XGBoost'] = y_pred\n",
    "resultsDict['XGBoost']\n",
    "#reg.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### XGBoost Tuner\n",
    "Use computed values from below in above regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m xgbr \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBRegressor(seed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m      8\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgbr,\n\u001b[1;32m      9\u001b[0m                          param_distributions\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m     10\u001b[0m                          scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m                          n_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m     12\u001b[0m                          verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, clf\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLowest RMSE: \u001b[39m\u001b[38;5;124m\"\u001b[39m, (\u001b[38;5;241m-\u001b[39mclf\u001b[38;5;241m.\u001b[39mbest_score_)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2.0\u001b[39m))\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:891\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    885\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    886\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    887\u001b[0m     )\n\u001b[1;32m    889\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 891\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    895\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:1766\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1766\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1767\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1768\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[1;32m   1769\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:838\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    832\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    834\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    835\u001b[0m         )\n\u001b[1;32m    836\u001b[0m     )\n\u001b[0;32m--> 838\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    857\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    859\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    860\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_original_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1047\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pre_dispatch \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[38;5;66;03m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[38;5;66;03m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;66;03m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs\u001b[38;5;241m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_async\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mImmediateResult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;66;03m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m parallel_backend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;28;01mfor\u001b[39;00m func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems]\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:680\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    678\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    679\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 680\u001b[0m         \u001b[43mestimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    683\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    684\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/xgboost/core.py:506\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    505\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 506\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:789\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m    786\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    788\u001b[0m model, feval, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, eval_metric, params)\n\u001b[0;32m--> 789\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/xgboost/training.py:188\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(params, dtrain, num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, evals\u001b[38;5;241m=\u001b[39m(), obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, feval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    116\u001b[0m           maximize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, evals_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    117\u001b[0m           verbose_eval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, xgb_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# pylint: disable=too-many-statements,too-many-branches, attribute-defined-outside-init\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;124;03m\"\"\"Train a booster with given parameters.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \n\u001b[1;32m    121\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Booster : a trained booster model\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     bst \u001b[38;5;241m=\u001b[39m \u001b[43m_train_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxgb_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bst\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/xgboost/training.py:81\u001b[0m, in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callbacks\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.8/site-packages/xgboost/core.py:1680\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_features(dtrain)\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1680\u001b[0m     _check_call(\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1681\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1682\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1684\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = { 'max_depth': [3, 5, 6, 10, 15, 20],\n",
    "           'learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "           'subsample': np.arange(0.5, 1.0, 0.1),\n",
    "           'colsample_bytree': np.arange(0.4, 1.0, 0.1),\n",
    "           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),\n",
    "           'n_estimators': [100, 500, 1000]}\n",
    "xgbr = xgb.XGBRegressor(seed = 20)\n",
    "clf = RandomizedSearchCV(estimator=xgbr,\n",
    "                         param_distributions=params,\n",
    "                         scoring='neg_mean_squared_error',\n",
    "                         n_iter=25,\n",
    "                         verbose=1)\n",
    "clf.fit(x_train, y_train)\n",
    "print(\"Best parameters:\", clf.best_params_)\n",
    "print(\"Lowest RMSE: \", (-clf.best_score_)**(1/2.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 85.59485078951491,\n",
       " 'rmse': 121.57430276717626,\n",
       " 'mape': 0.180563846590471,\n",
       " 'r2': 0.7885456577019125}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lightGBM = lgb.LGBMRegressor()\n",
    "lightGBM.fit(x_train, y_train)\n",
    "y_pred = lightGBM.predict(x_cv)\n",
    "\n",
    "resultsDict['Lightgbm'] = evaluate(y_cv, y_pred)\n",
    "predictionsDict['Lightgbm'] = y_pred\n",
    "\n",
    "#r2_score(y_cv, y_pred)\n",
    "resultsDict['Lightgbm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NeuralProphet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency B corresponds to 97.331% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency B corresponds to 97.179% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de6ff8d958b4abbb056ed24f1e4ead0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 4.61E-02, min: 5.62E-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f31bf009eca4186ada07c784a372374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 5.51E-02, min: 3.93E-01\n",
      "INFO - (NP.forecaster._init_train_loader) - lr-range-test selected learning rate: 6.33E-02\n",
      "Epoch[271/271]: 100%|â–ˆ| 271/271 [00:04<00:00, 60.01it/s, SmoothL1Loss=0.00555, M\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency B corresponds to 96.907% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.forecaster._evaluate) - Validation metrics:    SmoothL1Loss     MAE    RMSE\n",
      "1         0.024 176.629 220.533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SmoothL1Loss</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023981</td>\n",
       "      <td>176.628906</td>\n",
       "      <td>220.533447</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SmoothL1Loss         MAE        RMSE\n",
       "0      0.023981  176.628906  220.533447"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuralprophet import NeuralProphet\n",
    "ts = df[['Call Date','Total Incoming Calls']]\n",
    "ts.columns = ['ds', 'y'] \n",
    "\n",
    "m = NeuralProphet(\n",
    "    growth='linear',\n",
    "    seasonality_mode='additive',\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True\n",
    ").add_country_holidays(country_name='US')\n",
    "\n",
    "df_train, df_test = m.split_df(df=ts, freq=\"D\", valid_p=0.2)\n",
    "metrics_train = m.fit(df_train, freq=\"D\")\n",
    "metrics_test = m.test(df=df_test)\n",
    "\n",
    "metrics_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>yhat1</th>\n",
       "      <th>residual1</th>\n",
       "      <th>trend</th>\n",
       "      <th>season_weekly</th>\n",
       "      <th>ts_np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>296</td>\n",
       "      <td>240.962784</td>\n",
       "      <td>-55.037216</td>\n",
       "      <td>-65.105156</td>\n",
       "      <td>306.067932</td>\n",
       "      <td>244.653656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>381</td>\n",
       "      <td>336.942902</td>\n",
       "      <td>-44.057098</td>\n",
       "      <td>-68.344604</td>\n",
       "      <td>405.287506</td>\n",
       "      <td>338.533478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>363</td>\n",
       "      <td>362.602936</td>\n",
       "      <td>-0.397064</td>\n",
       "      <td>-69.424416</td>\n",
       "      <td>432.027374</td>\n",
       "      <td>364.341644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>305</td>\n",
       "      <td>342.218201</td>\n",
       "      <td>37.218201</td>\n",
       "      <td>-70.504227</td>\n",
       "      <td>412.722443</td>\n",
       "      <td>347.549957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>304</td>\n",
       "      <td>307.004761</td>\n",
       "      <td>3.004761</td>\n",
       "      <td>-71.584038</td>\n",
       "      <td>378.588806</td>\n",
       "      <td>310.214752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>2021-12-09</td>\n",
       "      <td>882</td>\n",
       "      <td>956.412842</td>\n",
       "      <td>74.412842</td>\n",
       "      <td>577.824036</td>\n",
       "      <td>378.588806</td>\n",
       "      <td>958.672241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>2021-12-10</td>\n",
       "      <td>792</td>\n",
       "      <td>887.842712</td>\n",
       "      <td>95.842712</td>\n",
       "      <td>581.774780</td>\n",
       "      <td>306.067932</td>\n",
       "      <td>889.802490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>2021-12-13</td>\n",
       "      <td>941</td>\n",
       "      <td>998.914368</td>\n",
       "      <td>57.914368</td>\n",
       "      <td>593.626831</td>\n",
       "      <td>405.287506</td>\n",
       "      <td>999.214966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>2021-12-14</td>\n",
       "      <td>948</td>\n",
       "      <td>1029.604614</td>\n",
       "      <td>81.604614</td>\n",
       "      <td>597.577271</td>\n",
       "      <td>432.027374</td>\n",
       "      <td>1030.200439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>985</td>\n",
       "      <td>1014.250427</td>\n",
       "      <td>29.250427</td>\n",
       "      <td>601.528015</td>\n",
       "      <td>412.722443</td>\n",
       "      <td>1018.586243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>487 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ds    y        yhat1  residual1       trend  season_weekly  \\\n",
       "0   2020-01-17  296   240.962784 -55.037216  -65.105156     306.067932   \n",
       "1   2020-01-20  381   336.942902 -44.057098  -68.344604     405.287506   \n",
       "2   2020-01-21  363   362.602936  -0.397064  -69.424416     432.027374   \n",
       "3   2020-01-22  305   342.218201  37.218201  -70.504227     412.722443   \n",
       "4   2020-01-23  304   307.004761   3.004761  -71.584038     378.588806   \n",
       "..         ...  ...          ...        ...         ...            ...   \n",
       "482 2021-12-09  882   956.412842  74.412842  577.824036     378.588806   \n",
       "483 2021-12-10  792   887.842712  95.842712  581.774780     306.067932   \n",
       "484 2021-12-13  941   998.914368  57.914368  593.626831     405.287506   \n",
       "485 2021-12-14  948  1029.604614  81.604614  597.577271     432.027374   \n",
       "486 2021-12-15  985  1014.250427  29.250427  601.528015     412.722443   \n",
       "\n",
       "           ts_np  \n",
       "0     244.653656  \n",
       "1     338.533478  \n",
       "2     364.341644  \n",
       "3     347.549957  \n",
       "4     310.214752  \n",
       "..           ...  \n",
       "482   958.672241  \n",
       "483   889.802490  \n",
       "484   999.214966  \n",
       "485  1030.200439  \n",
       "486  1018.586243  \n",
       "\n",
       "[487 rows x 7 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Compare regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residuals correlation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3ad98_row0_col0, #T_3ad98_row1_col1, #T_3ad98_row2_col2 {\n",
       "  background-color: #b40426;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ad98_row0_col1, #T_3ad98_row0_col2, #T_3ad98_row1_col0 {\n",
       "  background-color: #3b4cc0;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3ad98_row1_col2 {\n",
       "  background-color: #a6c4fe;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ad98_row2_col0 {\n",
       "  background-color: #a9c6fd;\n",
       "  color: #000000;\n",
       "}\n",
       "#T_3ad98_row2_col1 {\n",
       "  background-color: #e9d5cb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3ad98\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3ad98_level0_col0\" class=\"col_heading level0 col0\" >RandomForest</th>\n",
       "      <th id=\"T_3ad98_level0_col1\" class=\"col_heading level0 col1\" >Lightgbm</th>\n",
       "      <th id=\"T_3ad98_level0_col2\" class=\"col_heading level0 col2\" >XGBoost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3ad98_level0_row0\" class=\"row_heading level0 row0\" >RandomForest</th>\n",
       "      <td id=\"T_3ad98_row0_col0\" class=\"data row0 col0\" >1.000000</td>\n",
       "      <td id=\"T_3ad98_row0_col1\" class=\"data row0 col1\" >0.793971</td>\n",
       "      <td id=\"T_3ad98_row0_col2\" class=\"data row0 col2\" >0.862256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ad98_level0_row1\" class=\"row_heading level0 row1\" >Lightgbm</th>\n",
       "      <td id=\"T_3ad98_row1_col0\" class=\"data row1 col0\" >0.793971</td>\n",
       "      <td id=\"T_3ad98_row1_col1\" class=\"data row1 col1\" >1.000000</td>\n",
       "      <td id=\"T_3ad98_row1_col2\" class=\"data row1 col2\" >0.906895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3ad98_level0_row2\" class=\"row_heading level0 row2\" >XGBoost</th>\n",
       "      <td id=\"T_3ad98_row2_col0\" class=\"data row2 col0\" >0.862256</td>\n",
       "      <td id=\"T_3ad98_row2_col1\" class=\"data row2 col1\" >0.906895</td>\n",
       "      <td id=\"T_3ad98_row2_col2\" class=\"data row2 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x166631e50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = ['RandomForest',\n",
    "          'Lightgbm',\n",
    "          'XGBoost']\n",
    "resis = pd.DataFrame(data={k: y_cv -\n",
    "                              v for k, v in predictionsDict.items()})[models]\n",
    "corr = resis.corr()\n",
    "print(\"Residuals correlation\")\n",
    "corr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def bar_metrics(resultsDict):\n",
    "    df = pd.DataFrame.from_dict(resultsDict)\n",
    "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "    pallette = plt.cm.get_cmap(\"tab20c\", len(df.columns))\n",
    "    colors = [pallette(x) for x in range(len(df.columns))]\n",
    "    color_dict = dict(zip(df.columns, colors))\n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "\n",
    "    # MAE plot\n",
    "    fig.add_subplot(2, 2, 1)\n",
    "    df.loc[\"mae\"].sort_values().plot(\n",
    "        kind=\"bar\",\n",
    "        colormap=\"Paired\",\n",
    "        color=[color_dict.get(x, \"#333333\") for x in df.loc[\"mae\"].sort_values().index],\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.title(\"MAE Metric, lower is better\")\n",
    "    fig.add_subplot(2, 2, 2)\n",
    "    df.loc[\"rmse\"].sort_values().plot(\n",
    "        kind=\"bar\",\n",
    "        colormap=\"Paired\",\n",
    "        color=[\n",
    "            color_dict.get(x, \"#333333\") for x in df.loc[\"rmse\"].sort_values().index\n",
    "        ],\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.title(\"RMSE Metric, lower is better\")\n",
    "    fig.add_subplot(2, 2, 3)\n",
    "    df.loc[\"mape\"].sort_values().plot(\n",
    "        kind=\"bar\",\n",
    "        colormap=\"Paired\",\n",
    "        color=[\n",
    "            color_dict.get(x, \"#333333\") for x in df.loc[\"mape\"].sort_values().index\n",
    "        ],\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.title(\"MAPE Metric, lower is better\")\n",
    "    fig.add_subplot(2, 2, 4)\n",
    "    df.loc[\"r2\"].sort_values(ascending=False).plot(\n",
    "        kind=\"bar\",\n",
    "        colormap=\"Paired\",\n",
    "        color=[\n",
    "            color_dict.get(x, \"#333333\")\n",
    "            for x in df.loc[\"r2\"].sort_values(ascending=False).index\n",
    "        ],\n",
    "    )\n",
    "    plt.legend()\n",
    "    plt.title(\"R2 Metric, higher is better\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "bar_metrics(resultsDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "### Fit models and export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency B corresponds to 97.331% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.config.init_data_params) - Setting normalization to global as only one dataframe provided for training.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set epochs to 248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab497dce97ba477289e717a013f7d5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 3.70E-02, min: 2.14E-01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2a33166e5064e2db4a3509cffd1e7b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils_torch.lr_range_test) - lr-range-test results: steep: 4.41E-02, min: 2.14E-01\n",
      "INFO - (NP.forecaster._init_train_loader) - lr-range-test selected learning rate: 5.46E-02\n",
      "Epoch[248/248]: 100%|â–ˆ| 248/248 [00:04<00:00, 49.74it/s, SmoothL1Loss=0.00736, M\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SmoothL1Loss</th>\n",
       "      <th>MAE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>RegLoss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.049896</td>\n",
       "      <td>1488.742326</td>\n",
       "      <td>1738.151159</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.936727</td>\n",
       "      <td>1366.272116</td>\n",
       "      <td>1609.911885</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.820752</td>\n",
       "      <td>1243.328538</td>\n",
       "      <td>1481.848710</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.698965</td>\n",
       "      <td>1112.891124</td>\n",
       "      <td>1324.252003</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.577710</td>\n",
       "      <td>982.581726</td>\n",
       "      <td>1176.153682</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>0.007367</td>\n",
       "      <td>88.183845</td>\n",
       "      <td>116.611393</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>0.007359</td>\n",
       "      <td>88.145705</td>\n",
       "      <td>115.670481</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>0.007358</td>\n",
       "      <td>88.159093</td>\n",
       "      <td>115.773716</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>0.007357</td>\n",
       "      <td>88.150961</td>\n",
       "      <td>116.366335</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.007356</td>\n",
       "      <td>88.147516</td>\n",
       "      <td>116.755892</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SmoothL1Loss          MAE         RMSE  RegLoss\n",
       "0        1.049896  1488.742326  1738.151159      0.0\n",
       "1        0.936727  1366.272116  1609.911885      0.0\n",
       "2        0.820752  1243.328538  1481.848710      0.0\n",
       "3        0.698965  1112.891124  1324.252003      0.0\n",
       "4        0.577710   982.581726  1176.153682      0.0\n",
       "..            ...          ...          ...      ...\n",
       "243      0.007367    88.183845   116.611393      0.0\n",
       "244      0.007359    88.145705   115.670481      0.0\n",
       "245      0.007358    88.159093   115.773716      0.0\n",
       "246      0.007357    88.150961   116.366335      0.0\n",
       "247      0.007356    88.147516   116.755892      0.0\n",
       "\n",
       "[248 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RandomForest\n",
    "reg_rf = RandomForestRegressor()\n",
    "reg_rf.fit(predictors, target)\n",
    "\n",
    "#XGBoost\n",
    "reg_xgb = xgb.XGBRegressor(objective='reg:squarederror',subsample=0.5, n_estimators=1000, max_depth=5, learning_rate=0.01, colsample_bytree=0.8, colsample_bylevel=0.8)\n",
    "reg_xgb.fit(predictors, target)\n",
    "\n",
    "#LightGBM\n",
    "reg_lgb = lgb.LGBMRegressor()\n",
    "reg_lgb.fit(predictors, target)\n",
    "\n",
    "#NeuralProphet\n",
    "ts_np = NeuralProphet(\n",
    "    growth='linear',\n",
    "    seasonality_mode='additive',\n",
    "    daily_seasonality=True,\n",
    "    weekly_seasonality=True,\n",
    "    yearly_seasonality=True\n",
    ").add_country_holidays(country_name='US')\n",
    "\n",
    "ts_np.fit(ts, freq=\"D\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.df_utils._infer_frequency) - Major frequency B corresponds to 97.331% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n",
      "INFO - (NP.df_utils._infer_frequency) - Major frequency B corresponds to 97.331% of the data.\n",
      "INFO - (NP.df_utils._infer_frequency) - Defined frequency is equal to major frequency - D\n"
     ]
    }
   ],
   "source": [
    "future = pd.read_excel('~/Downloads/calls_test.xlsx')\n",
    "future['Call Date'] = pd.to_datetime(future['Call Date'], format=\"%d.%m.%Y\")\n",
    "future['Holiday'] = future['Call Date'].isin(holidays).astype(int)\n",
    "prediction = future.drop(['Call Date'],axis=1)\n",
    "\n",
    "future['rf'] = reg_rf.predict(prediction)\n",
    "future['xgb'] = reg_xgb.predict(prediction)\n",
    "future['lgb'] = reg_lgb.predict(prediction)\n",
    "future['lgb'] = reg_lgb.predict(prediction)\n",
    "future['ts_np'] = ts_np.predict(ts).yhat1\n",
    "\n",
    "#future.to_csv('future-calls.csv',index=False)\n",
    "\n",
    "export = pd.concat([df, future])\n",
    "with pd.ExcelWriter(\"~/Downloads/calls.xlsx\", engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    export.to_excel(writer, 'Future', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Call Date</th>\n",
       "      <th>Year of Call Date</th>\n",
       "      <th>Month</th>\n",
       "      <th>Week of Call Date</th>\n",
       "      <th>Day of Call Date</th>\n",
       "      <th>Weekday of Call Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>rf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>lgb</th>\n",
       "      <th>ts_np</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-16</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>818.08</td>\n",
       "      <td>819.575684</td>\n",
       "      <td>900.910817</td>\n",
       "      <td>553.380005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-12-17</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>774.27</td>\n",
       "      <td>788.495605</td>\n",
       "      <td>866.373592</td>\n",
       "      <td>222.018417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-18</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>771.03</td>\n",
       "      <td>789.880615</td>\n",
       "      <td>866.355694</td>\n",
       "      <td>575.328613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-12-19</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>51</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>827.40</td>\n",
       "      <td>990.945618</td>\n",
       "      <td>1069.150701</td>\n",
       "      <td>530.708496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1304.31</td>\n",
       "      <td>1305.074585</td>\n",
       "      <td>1181.376708</td>\n",
       "      <td>469.048920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-12-21</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1311.99</td>\n",
       "      <td>1362.455933</td>\n",
       "      <td>1207.987257</td>\n",
       "      <td>367.028809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-12-22</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1264.64</td>\n",
       "      <td>1240.386597</td>\n",
       "      <td>1178.261743</td>\n",
       "      <td>405.067322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-12-23</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1150.57</td>\n",
       "      <td>1142.177734</td>\n",
       "      <td>1090.171674</td>\n",
       "      <td>401.616882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-12-24</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1052.38</td>\n",
       "      <td>987.111023</td>\n",
       "      <td>986.005509</td>\n",
       "      <td>362.182739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-12-25</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1101.98</td>\n",
       "      <td>1044.250244</td>\n",
       "      <td>984.895135</td>\n",
       "      <td>306.440796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-12-26</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>52</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1225.23</td>\n",
       "      <td>1235.684448</td>\n",
       "      <td>1171.764799</td>\n",
       "      <td>211.021500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2021-12-27</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1242.17</td>\n",
       "      <td>1244.439941</td>\n",
       "      <td>1169.603347</td>\n",
       "      <td>272.406525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2021-12-28</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1273.56</td>\n",
       "      <td>1298.442505</td>\n",
       "      <td>1194.631315</td>\n",
       "      <td>277.715546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-12-29</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1287.52</td>\n",
       "      <td>1279.365967</td>\n",
       "      <td>1191.417080</td>\n",
       "      <td>247.419724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-12-30</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1194.74</td>\n",
       "      <td>1204.270752</td>\n",
       "      <td>1133.032728</td>\n",
       "      <td>201.125702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>2021</td>\n",
       "      <td>12</td>\n",
       "      <td>53</td>\n",
       "      <td>31</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1075.71</td>\n",
       "      <td>1012.189697</td>\n",
       "      <td>1039.875042</td>\n",
       "      <td>115.393257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>947.88</td>\n",
       "      <td>771.610291</td>\n",
       "      <td>545.549927</td>\n",
       "      <td>206.556015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022-01-02</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1075.06</td>\n",
       "      <td>972.823303</td>\n",
       "      <td>586.171503</td>\n",
       "      <td>221.792511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022-01-03</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1077.29</td>\n",
       "      <td>977.635986</td>\n",
       "      <td>584.568353</td>\n",
       "      <td>201.308899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022-01-04</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1108.04</td>\n",
       "      <td>969.722168</td>\n",
       "      <td>579.015812</td>\n",
       "      <td>164.645111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2022-01-05</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1143.51</td>\n",
       "      <td>979.391296</td>\n",
       "      <td>579.015812</td>\n",
       "      <td>88.296730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2022-01-06</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1074.98</td>\n",
       "      <td>901.060059</td>\n",
       "      <td>536.631491</td>\n",
       "      <td>213.465454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2022-01-07</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>949.80</td>\n",
       "      <td>756.251526</td>\n",
       "      <td>534.570665</td>\n",
       "      <td>228.610321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2022-01-08</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>915.26</td>\n",
       "      <td>742.404053</td>\n",
       "      <td>534.570665</td>\n",
       "      <td>215.446091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2022-01-09</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1065.87</td>\n",
       "      <td>935.655762</td>\n",
       "      <td>574.791095</td>\n",
       "      <td>185.553375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2022-01-10</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1024.87</td>\n",
       "      <td>897.929871</td>\n",
       "      <td>575.070531</td>\n",
       "      <td>115.394592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1067.76</td>\n",
       "      <td>922.350464</td>\n",
       "      <td>577.724460</td>\n",
       "      <td>274.190338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2022-01-12</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1101.92</td>\n",
       "      <td>931.007629</td>\n",
       "      <td>577.724460</td>\n",
       "      <td>264.013885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2022-01-13</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1004.40</td>\n",
       "      <td>838.828979</td>\n",
       "      <td>544.560589</td>\n",
       "      <td>236.451126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2022-01-14</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>819.53</td>\n",
       "      <td>581.092407</td>\n",
       "      <td>539.457516</td>\n",
       "      <td>167.972244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2022-01-15</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>446.17</td>\n",
       "      <td>491.962250</td>\n",
       "      <td>325.627805</td>\n",
       "      <td>301.355194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2022-01-16</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>522.22</td>\n",
       "      <td>715.661743</td>\n",
       "      <td>379.103841</td>\n",
       "      <td>327.335052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2022-01-17</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>265.68</td>\n",
       "      <td>499.299103</td>\n",
       "      <td>402.336699</td>\n",
       "      <td>315.893158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>315.35</td>\n",
       "      <td>587.091553</td>\n",
       "      <td>390.190272</td>\n",
       "      <td>286.569977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2022-01-19</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>331.59</td>\n",
       "      <td>615.836487</td>\n",
       "      <td>397.255305</td>\n",
       "      <td>215.876862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2022-01-20</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>320.30</td>\n",
       "      <td>596.997009</td>\n",
       "      <td>365.541160</td>\n",
       "      <td>340.346313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2022-01-21</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>255.08</td>\n",
       "      <td>489.162354</td>\n",
       "      <td>332.369194</td>\n",
       "      <td>362.760925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2022-01-22</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>252.83</td>\n",
       "      <td>489.099548</td>\n",
       "      <td>332.369194</td>\n",
       "      <td>347.541962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2022-01-23</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>330.30</td>\n",
       "      <td>615.751404</td>\n",
       "      <td>417.805845</td>\n",
       "      <td>314.282532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2022-01-24</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>317.74</td>\n",
       "      <td>617.549561</td>\n",
       "      <td>156.806825</td>\n",
       "      <td>239.546509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2022-01-25</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>278.67</td>\n",
       "      <td>639.919312</td>\n",
       "      <td>158.832310</td>\n",
       "      <td>348.314850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2022-01-26</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>315.85</td>\n",
       "      <td>627.849976</td>\n",
       "      <td>153.896863</td>\n",
       "      <td>364.947021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2022-01-27</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>330.53</td>\n",
       "      <td>593.130371</td>\n",
       "      <td>199.617472</td>\n",
       "      <td>344.087036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2022-01-28</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>304.13</td>\n",
       "      <td>540.799927</td>\n",
       "      <td>187.340233</td>\n",
       "      <td>305.371399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2022-01-29</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>300.04</td>\n",
       "      <td>535.403992</td>\n",
       "      <td>187.340233</td>\n",
       "      <td>225.404266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2022-01-30</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>333.27</td>\n",
       "      <td>634.370850</td>\n",
       "      <td>229.992146</td>\n",
       "      <td>323.630463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>330.08</td>\n",
       "      <td>642.010986</td>\n",
       "      <td>229.992146</td>\n",
       "      <td>338.087006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Call Date  Year of Call Date  Month  Week of Call Date  Day of Call Date  \\\n",
       "0  2021-12-16               2021     12                 51                16   \n",
       "1  2021-12-17               2021     12                 51                17   \n",
       "2  2021-12-18               2021     12                 51                18   \n",
       "3  2021-12-19               2021     12                 51                19   \n",
       "4  2021-12-20               2021     12                 52                20   \n",
       "5  2021-12-21               2021     12                 52                21   \n",
       "6  2021-12-22               2021     12                 52                22   \n",
       "7  2021-12-23               2021     12                 52                23   \n",
       "8  2021-12-24               2021     12                 52                24   \n",
       "9  2021-12-25               2021     12                 52                25   \n",
       "10 2021-12-26               2021     12                 52                26   \n",
       "11 2021-12-27               2021     12                 53                27   \n",
       "12 2021-12-28               2021     12                 53                28   \n",
       "13 2021-12-29               2021     12                 53                29   \n",
       "14 2021-12-30               2021     12                 53                30   \n",
       "15 2021-12-31               2021     12                 53                31   \n",
       "16 2022-01-01               2022     12                  1                 1   \n",
       "17 2022-01-02               2022     12                  1                 2   \n",
       "18 2022-01-03               2022     12                  2                 3   \n",
       "19 2022-01-04               2022     12                  2                 4   \n",
       "20 2022-01-05               2022     12                  2                 5   \n",
       "21 2022-01-06               2022     12                  2                 6   \n",
       "22 2022-01-07               2022     12                  2                 7   \n",
       "23 2022-01-08               2022     12                  2                 8   \n",
       "24 2022-01-09               2022     12                  2                 9   \n",
       "25 2022-01-10               2022     12                  3                10   \n",
       "26 2022-01-11               2022     12                  3                11   \n",
       "27 2022-01-12               2022     12                  3                12   \n",
       "28 2022-01-13               2022     12                  3                13   \n",
       "29 2022-01-14               2022     12                  3                14   \n",
       "30 2022-01-15               2022     12                  3                15   \n",
       "31 2022-01-16               2022     12                  3                16   \n",
       "32 2022-01-17               2022     12                  4                17   \n",
       "33 2022-01-18               2022     12                  4                18   \n",
       "34 2022-01-19               2022     12                  4                19   \n",
       "35 2022-01-20               2022     12                  4                20   \n",
       "36 2022-01-21               2022     12                  4                21   \n",
       "37 2022-01-22               2022     12                  4                22   \n",
       "38 2022-01-23               2022     12                  4                23   \n",
       "39 2022-01-24               2022     12                  5                24   \n",
       "40 2022-01-25               2022     12                  5                25   \n",
       "41 2022-01-26               2022     12                  5                26   \n",
       "42 2022-01-27               2022     12                  5                27   \n",
       "43 2022-01-28               2022     12                  5                28   \n",
       "44 2022-01-29               2022     12                  5                29   \n",
       "45 2022-01-30               2022     12                  5                30   \n",
       "46 2022-01-31               2022     12                  6                31   \n",
       "\n",
       "    Weekday of Call Date  Holiday       rf          xgb          lgb  \\\n",
       "0                      5        0   818.08   819.575684   900.910817   \n",
       "1                      6        0   774.27   788.495605   866.373592   \n",
       "2                      7        0   771.03   789.880615   866.355694   \n",
       "3                      1        0   827.40   990.945618  1069.150701   \n",
       "4                      2        0  1304.31  1305.074585  1181.376708   \n",
       "5                      3        0  1311.99  1362.455933  1207.987257   \n",
       "6                      4        0  1264.64  1240.386597  1178.261743   \n",
       "7                      5        0  1150.57  1142.177734  1090.171674   \n",
       "8                      6        1  1052.38   987.111023   986.005509   \n",
       "9                      7        0  1101.98  1044.250244   984.895135   \n",
       "10                     1        0  1225.23  1235.684448  1171.764799   \n",
       "11                     2        0  1242.17  1244.439941  1169.603347   \n",
       "12                     3        0  1273.56  1298.442505  1194.631315   \n",
       "13                     4        0  1287.52  1279.365967  1191.417080   \n",
       "14                     5        0  1194.74  1204.270752  1133.032728   \n",
       "15                     6        1  1075.71  1012.189697  1039.875042   \n",
       "16                     7        0   947.88   771.610291   545.549927   \n",
       "17                     1        0  1075.06   972.823303   586.171503   \n",
       "18                     2        0  1077.29   977.635986   584.568353   \n",
       "19                     3        0  1108.04   969.722168   579.015812   \n",
       "20                     4        0  1143.51   979.391296   579.015812   \n",
       "21                     5        0  1074.98   901.060059   536.631491   \n",
       "22                     6        0   949.80   756.251526   534.570665   \n",
       "23                     7        0   915.26   742.404053   534.570665   \n",
       "24                     1        0  1065.87   935.655762   574.791095   \n",
       "25                     2        0  1024.87   897.929871   575.070531   \n",
       "26                     3        0  1067.76   922.350464   577.724460   \n",
       "27                     4        0  1101.92   931.007629   577.724460   \n",
       "28                     5        0  1004.40   838.828979   544.560589   \n",
       "29                     6        0   819.53   581.092407   539.457516   \n",
       "30                     7        0   446.17   491.962250   325.627805   \n",
       "31                     1        0   522.22   715.661743   379.103841   \n",
       "32                     2        1   265.68   499.299103   402.336699   \n",
       "33                     3        0   315.35   587.091553   390.190272   \n",
       "34                     4        0   331.59   615.836487   397.255305   \n",
       "35                     5        0   320.30   596.997009   365.541160   \n",
       "36                     6        0   255.08   489.162354   332.369194   \n",
       "37                     7        0   252.83   489.099548   332.369194   \n",
       "38                     1        0   330.30   615.751404   417.805845   \n",
       "39                     2        0   317.74   617.549561   156.806825   \n",
       "40                     3        0   278.67   639.919312   158.832310   \n",
       "41                     4        0   315.85   627.849976   153.896863   \n",
       "42                     5        0   330.53   593.130371   199.617472   \n",
       "43                     6        0   304.13   540.799927   187.340233   \n",
       "44                     7        0   300.04   535.403992   187.340233   \n",
       "45                     1        0   333.27   634.370850   229.992146   \n",
       "46                     2        0   330.08   642.010986   229.992146   \n",
       "\n",
       "         ts_np  \n",
       "0   553.380005  \n",
       "1   222.018417  \n",
       "2   575.328613  \n",
       "3   530.708496  \n",
       "4   469.048920  \n",
       "5   367.028809  \n",
       "6   405.067322  \n",
       "7   401.616882  \n",
       "8   362.182739  \n",
       "9   306.440796  \n",
       "10  211.021500  \n",
       "11  272.406525  \n",
       "12  277.715546  \n",
       "13  247.419724  \n",
       "14  201.125702  \n",
       "15  115.393257  \n",
       "16  206.556015  \n",
       "17  221.792511  \n",
       "18  201.308899  \n",
       "19  164.645111  \n",
       "20   88.296730  \n",
       "21  213.465454  \n",
       "22  228.610321  \n",
       "23  215.446091  \n",
       "24  185.553375  \n",
       "25  115.394592  \n",
       "26  274.190338  \n",
       "27  264.013885  \n",
       "28  236.451126  \n",
       "29  167.972244  \n",
       "30  301.355194  \n",
       "31  327.335052  \n",
       "32  315.893158  \n",
       "33  286.569977  \n",
       "34  215.876862  \n",
       "35  340.346313  \n",
       "36  362.760925  \n",
       "37  347.541962  \n",
       "38  314.282532  \n",
       "39  239.546509  \n",
       "40  348.314850  \n",
       "41  364.947021  \n",
       "42  344.087036  \n",
       "43  305.371399  \n",
       "44  225.404266  \n",
       "45  323.630463  \n",
       "46  338.087006  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dorian",
   "language": "python",
   "name": "dorian"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
